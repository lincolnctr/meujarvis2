import streamlit as st
from groq import Groq

# 1. Configura√ß√£o visual da p√°gina (O "Corpo" do Jarvis)
st.set_page_config(page_title="J.A.R.V.I.S.", page_icon="ü§ñ")

# Estilo para deixar com cara de terminal de tecnologia
st.markdown("""
    <style>
    .stApp { background-color: #0e1117; }
    .stChatMessage { border-radius: 15px; border: 1px solid #00d4ff33; }
    h1 { color: #00d4ff; text-shadow: 2px 2px #000; }
    </style>
    """, unsafe_allow_html=True)

st.title("J.A.R.V.I.S. üõ°Ô∏è")
st.caption("Protocolo de Interface Web - Senhor Lincoln")

# 2. Conex√£o com o c√©rebro (Groq)
# No Streamlit Cloud, vamos usar 'secrets' para a chave ficar protegida
if "GROQ_API_KEY" in st.secrets:
    api_key = st.secrets["GROQ_API_KEY"]
else:
    # Se voc√™ for testar localmente, coloque a chave aqui
    api_key = st.secrets["GROQ_API_KEY"]

client = Groq(api_key=api_key)

# 3. Mem√≥ria da conversa (Para ele n√£o esquecer o que voc√™ disse na mensagem anterior)
if "messages" not in st.session_state:
    st.session_state.messages = []

# Exibe o hist√≥rico de mensagens na tela
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 4. Campo de entrada (Onde voc√™ digita)
if prompt := st.chat_input("Em que posso ajudar, Senhor?"):
    # Adiciona sua pergunta ao hist√≥rico
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Resposta do Jarvis
    with st.chat_message("assistant"):
        try:
            # Instru√ß√£o de Personalidade
            instrucoes = "Voc√™ √© o JARVIS. Responda de forma elegante, curta, t√©cnica e chame o usu√°rio de Senhor Lincoln. Foque em ser √∫til e direto."
            
            full_messages = [{"role": "system", "content": instrucoes}] + [
                {"role": m["role"], "content": m["content"]} for m in st.session_state.messages
            ]

            completion = client.chat.completions.create(
                messages=full_messages,
                model="llama-3.1-8b-instant",
            )
            
            response = completion.choices[0].message.content
            st.markdown(response)
            
            # Guarda a resposta dele na mem√≥ria
            st.session_state.messages.append({"role": "assistant", "content": response})
            
        except Exception as e:
            st.error(f"Senhor, tive um problema no servidor: {e}")
